---
phase: 06-transcript-analysis
plan: "01"
type: execute
wave: 1
depends_on: []
files_modified:
  - hive/bin/hive-tools.js
  - agents/hive-recall-analyst.md
  - commands/hive/analyze-session.md
  - hive/workflows/analyze-session.md
  - .claude/agents/hive-recall-analyst.md
  - .claude/commands/hive/analyze-session.md
  - .claude/hive/workflows/analyze-session.md
autonomous: true

must_haves:
  truths:
    - "Running `hive-tools.js telemetry transcript` extracts and condenses a Claude Code session transcript into a structured JSON payload with message counts, token usage, tool usage, and condensed text"
    - "Running `hive-tools.js telemetry transcript` with transcript_analysis disabled in config produces an error message"
    - "The hive-recall-analyst agent definition exists and follows the established agent pattern (frontmatter with name/description/tools/color, role section, analysis framework, structured JSON output format)"
    - "The /hive:analyze-session command and workflow exist and follow the insights.md pattern (command dispatches to workflow, workflow orchestrates extraction + agent spawn + event emission)"
  artifacts:
    - path: "hive/bin/hive-tools.js"
      provides: "telemetry transcript subcommand with resolveClaudeProjectDir, findLatestTranscript, cmdTelemetryTranscript"
      contains: "cmdTelemetryTranscript"
    - path: "agents/hive-recall-analyst.md"
      provides: "Analyst agent definition with quality dimensions and structured JSON output"
      contains: "hive-recall-analyst"
    - path: "commands/hive/analyze-session.md"
      provides: "Slash command entry point for /hive:analyze-session"
      contains: "analyze-session"
    - path: "hive/workflows/analyze-session.md"
      provides: "Workflow orchestrating transcript extraction, agent spawn, and event emission"
      contains: "telemetry transcript"
    - path: ".claude/agents/hive-recall-analyst.md"
      provides: "Installed copy of analyst agent"
      contains: "hive-recall-analyst"
    - path: ".claude/commands/hive/analyze-session.md"
      provides: "Installed copy of analyze-session command"
      contains: "analyze-session"
    - path: ".claude/hive/workflows/analyze-session.md"
      provides: "Installed copy of analyze-session workflow"
      contains: "telemetry transcript"
  key_links:
    - from: "hive/workflows/analyze-session.md"
      to: "hive/bin/hive-tools.js"
      via: "telemetry transcript CLI invocation"
      pattern: "hive-tools\\.js telemetry transcript"
    - from: "hive/workflows/analyze-session.md"
      to: "agents/hive-recall-analyst.md"
      via: "Task() agent spawn"
      pattern: "hive-recall-analyst"
    - from: "hive/workflows/analyze-session.md"
      to: "hive/bin/hive-tools.js"
      via: "telemetry emit session_summary"
      pattern: "telemetry emit session_summary"
    - from: "commands/hive/analyze-session.md"
      to: "hive/workflows/analyze-session.md"
      via: "execution_context reference"
      pattern: "analyze-session\\.md"
    - from: "hive/bin/hive-tools.js"
      to: "telemetry transcript router"
      via: "subcommand dispatch in telemetry case"
      pattern: "transcript"
---

<objective>
Create the complete single-session transcript analysis pipeline: CLI extraction command, analyst agent, and command/workflow pair.

Purpose: Enable deep post-hoc analysis of Claude Code session transcripts to identify reasoning quality, wasted context, retry patterns, and user preference signals that automated hooks and workflow events cannot capture (TRANS-01, TRANS-02).

Output: Working `telemetry transcript` CLI command, `hive-recall-analyst` agent, `/hive:analyze-session` command and workflow, plus all installed mirror copies.
</objective>

<execution_context>
@./.claude/hive/workflows/execute-plan.md
@./.claude/hive/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-transcript-analysis/06-RESEARCH.md

# Existing patterns to follow
@commands/hive/insights.md
@hive/workflows/insights.md
@agents/hive-verifier.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add telemetry transcript CLI command and analyst agent definition</name>
  <files>hive/bin/hive-tools.js, agents/hive-recall-analyst.md</files>
  <action>
**In hive/bin/hive-tools.js:**

1. Add three new functions near the existing telemetry helpers (after `rotateIfNeeded` and before `cmdTelemetryEmit`):

   a. `resolveClaudeProjectDir(cwd)` -- Resolves the Claude Code projects directory for the given cwd. Uses `require('os').homedir()` + `path.join(homedir, '.claude', 'projects', cwd.replace(/\//g, '-'))`. Returns the directory path. See research Pattern 1 / Code Examples section for the exact encoding convention (e.g., `/home/dico/project` becomes `-home-dico-project`).

   b. `findLatestTranscript(projectDir)` -- Lists `.jsonl` files in the projectDir, sorts by mtime descending, returns the path of the most recent one (or null). Wraps in try/catch returning null on failure. See research Code Examples for exact implementation.

   c. `cmdTelemetryTranscript(cwd, sessionId, raw)` -- The main command function:
      - Check `getTelemetryConfig(cwd).transcript_analysis` -- if false, call `error('Transcript analysis is disabled. Set transcript_analysis: true in config.json telemetry section')`.
      - Resolve transcript path: if `sessionId` provided, use `path.join(resolveClaudeProjectDir(cwd), sessionId + '.jsonl')`. Otherwise use `findLatestTranscript(resolveClaudeProjectDir(cwd))`.
      - If no transcript found, `error('No transcript found' + (sessionId ? ' for session ' + sessionId : ''))`.
      - Read file, split by newlines, filter empty lines.
      - Parse each line with try/catch (skip malformed). Filter to `type === 'user'` or `type === 'assistant'` messages.
      - Aggregate metrics from assistant messages: `totalInputTokens` (sum of `usage.input_tokens` + `cache_read_input_tokens` + `cache_creation_input_tokens`), `totalOutputTokens` (sum of `usage.output_tokens`), `toolUses` object (count by tool name from `content` blocks with `type === 'tool_use'`), `toolErrors` count.
      - Build condensed transcript array: for each message, extract role, text (truncated to 2000 chars), tools used (for assistant), timestamp. IMPORTANT: Skip `thinking` content blocks from assistant messages (they waste analyst context for minimal value).
      - Validate minimum content: if fewer than 5 user+assistant messages, `error('Session too short for meaningful analysis (found ' + messages.length + ' messages, minimum 5)')`.
      - Output result object via `output(result, raw)` with fields: `session_id`, `transcript_path`, `message_count`, `user_turns`, `assistant_turns`, `total_input_tokens`, `total_output_tokens`, `tool_uses`, `condensed_transcript`.

2. Add the `transcript` subcommand to the telemetry case dispatcher (around line 5168, after the `rotate` branch and before the `else` error branch):
   ```
   } else if (subcommand === 'transcript') {
     const sessionId = args[2] && !args[2].startsWith('--') ? args[2] : null;
     cmdTelemetryTranscript(cwd, sessionId, raw);
   }
   ```
   Also update the error message to include 'transcript' in the available subcommands list.

**In agents/hive-recall-analyst.md:**

Create a new agent definition following the exact pattern of `agents/hive-verifier.md` (frontmatter with name/description/tools/color, then role/process/output sections in XML tags):

Frontmatter:
```yaml
---
name: hive-recall-analyst
description: Analyzes session transcripts for reasoning quality, wasted context, retry patterns, and produces structured session_summary output for telemetry events.
tools: Read, Bash
color: yellow
---
```

Body sections:

`<role>`: You are a Hive Recall analyst. You examine condensed session transcripts to identify quality patterns that automated hooks and workflow events cannot capture. You receive pre-processed transcript data (extracted by the CLI) and produce structured analysis.

`<analysis_framework>`: Define 4 quality dimensions with scoring guidance:
1. **Reasoning Quality** (0-100): instruction accuracy, purposeful vs redundant tool uses, error recovery efficiency
2. **Wasted Context** (0-100% waste): repeated tool calls with same args, reading unused files, dead-end reasoning chains, unnecessary re-verification
3. **Retry Patterns**: tool errors followed by retry, same operation attempted multiple ways, circular reasoning
4. **User Interaction Quality**: corrections needed, clarifying questions, response scope appropriateness

`<privacy_rules>`: CRITICAL section. Patterns and recommendations must be GENERIC and actionable. Never include file paths, variable names, code snippets, or user-specific content in output. Say "Repeated file reads without using content" not "Read src/utils/auth.ts 3 times without using it". This ensures session_summary events contain metadata only, never raw transcript content.

`<output_format>`: Return structured analysis as a JSON code block with these fields:
- `quality_score` (0-100 integer)
- `waste_pct` (0-100 integer)
- `patterns` (array of max 5 generic strings describing observed patterns)
- `recommendations` (array of max 3 generic actionable strings)
- `user_preference_signals` (array of max 3 strings about implicit user preferences)
- `agent_behavior_notes` (array of max 3 strings about agent behavior observations)

Include the exact JSON structure example from the research (see Research Pattern 2).

`<success_criteria>`:
- [ ] All 4 quality dimensions assessed
- [ ] quality_score and waste_pct are integers 0-100
- [ ] patterns, recommendations, user_preference_signals are generic (no file paths, no code)
- [ ] Output is valid JSON in a code block
  </action>
  <verify>
1. Run `node ./hive/bin/hive-tools.js telemetry transcript --help 2>&1` or just run it without args -- should show an error about transcript_analysis being disabled (since default config has it false) OR "No transcript found" if config enables it. The point is that the subcommand is routed correctly and does not produce "Unknown telemetry subcommand".
2. Verify the agent file exists: `cat agents/hive-recall-analyst.md | head -5` should show the frontmatter with `name: hive-recall-analyst`.
3. Grep for the new functions: `grep -c 'cmdTelemetryTranscript\|resolveClaudeProjectDir\|findLatestTranscript' hive/bin/hive-tools.js` should return 3+ matches.
  </verify>
  <done>
The `telemetry transcript` CLI subcommand correctly routes, checks config, resolves transcript paths, extracts and condenses user+assistant messages with metrics, and outputs structured JSON. The `hive-recall-analyst.md` agent file exists with proper frontmatter, analysis framework, privacy rules, and structured JSON output format.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create analyze-session command, workflow, and all installed mirror copies</name>
  <files>commands/hive/analyze-session.md, hive/workflows/analyze-session.md, .claude/agents/hive-recall-analyst.md, .claude/commands/hive/analyze-session.md, .claude/hive/workflows/analyze-session.md</files>
  <action>
**In commands/hive/analyze-session.md:**

Follow the exact pattern of `commands/hive/insights.md`. Create a slash command definition:

```markdown
---
name: hive:analyze-session
description: Analyze a Claude Code session transcript for reasoning quality, wasted context, and patterns
allowed-tools:
  - Read
  - Bash
  - Write
  - Glob
  - Grep
  - Task
---
<objective>
Analyze a Claude Code session transcript using the hive-recall-analyst agent. Extracts transcript data, spawns the analyst, and emits a session_summary event.
</objective>

<execution_context>
@~/.claude/hive/workflows/analyze-session.md
</execution_context>

<process>
Execute the analyze-session workflow from @~/.claude/hive/workflows/analyze-session.md end-to-end.
If a session ID was provided in the user's command, pass it to the workflow.
</process>
```

Note: The `Task` tool must be in allowed-tools because the workflow spawns the analyst agent.

**In hive/workflows/analyze-session.md:**

Follow the pattern of `hive/workflows/insights.md`. Create a workflow with these steps:

`<purpose>`: Analyze a Claude Code session transcript for deep quality patterns using the hive-recall-analyst agent. Extracts transcript data via CLI, spawns the analyst, parses results, and emits a session_summary event.

`<process>` with these steps:

1. `check_config`: Run `node ~/.claude/hive/bin/hive-tools.js telemetry stats --raw` and check if transcript_analysis is enabled by examining config. If disabled, inform the user: "Transcript analysis is disabled. To enable, set `transcript_analysis: true` in your project's config.json telemetry section." Ask if they want to continue (they can enable it manually). If they decline, end.

2. `extract_transcript`: Run `node ~/.claude/hive/bin/hive-tools.js telemetry transcript [SESSION_ID] --raw` where SESSION_ID is optional (latest if not provided). Parse the JSON output. Display summary to user: "Found session with {user_turns} user turns, {assistant_turns} assistant turns, {total_input_tokens} input tokens." If the command errors (no transcript found, too short, disabled), display the error and end.

3. `analyze`: Spawn `hive-recall-analyst` via Task():
   - In the Task prompt, include: the condensed transcript from step 2, the metrics (token counts, tool usage), and instructions to analyze per the agent's framework.
   - Also pass telemetry stats context: run `node ~/.claude/hive/bin/hive-tools.js telemetry stats --raw` and include event counts so the analyst has quantitative context.
   - The agent will return a JSON code block with quality_score, waste_pct, patterns, recommendations, user_preference_signals, agent_behavior_notes.

4. `emit_event`: Parse the analyst's JSON output. Construct a session_summary event data object with: quality_score, waste_pct, patterns (max 5), recommendations (max 3), user_preferences (from user_preference_signals, max 3), metrics (user_turns, assistant_turns, total_input_tokens, total_output_tokens, tool_uses from the extraction step). Run: `node ~/.claude/hive/bin/hive-tools.js telemetry emit session_summary --data '{...}'`. Verify the emit succeeds.

5. `report`: Display the analysis results to the user in a readable format: quality score, waste percentage, patterns found, recommendations, user preference signals. Offer to regenerate the telemetry digest to incorporate the new session_summary: "Would you like to regenerate the insights digest to include this analysis?" If yes, run `node ~/.claude/hive/bin/hive-tools.js telemetry digest`.

IMPORTANT path convention: Source files in `hive/` use `~/.claude/` paths for referencing other hive files. The installed copies in `.claude/` use `./.claude/` paths. This is the established convention from Phases 2-5.

**Mirror copies:**

1. Copy `agents/hive-recall-analyst.md` to `.claude/agents/hive-recall-analyst.md` -- no path changes needed (agents don't reference hive paths).

2. Copy `commands/hive/analyze-session.md` to `.claude/commands/hive/analyze-session.md` -- change `@~/.claude/` to `@./.claude/` in the execution_context reference.

3. Copy `hive/workflows/analyze-session.md` to `.claude/hive/workflows/analyze-session.md` -- change all `~/.claude/` to `./.claude/` in CLI command paths.

Use `git add -f` for the `.claude/` files since `.claude` directory is in `.gitignore` (established pattern from Phase 2 and Phase 4).
  </action>
  <verify>
1. Verify all 5 files exist: `ls commands/hive/analyze-session.md hive/workflows/analyze-session.md .claude/agents/hive-recall-analyst.md .claude/commands/hive/analyze-session.md .claude/hive/workflows/analyze-session.md`
2. Verify source command references source workflow: `grep 'analyze-session.md' commands/hive/analyze-session.md`
3. Verify workflow references CLI transcript command: `grep 'telemetry transcript' hive/workflows/analyze-session.md`
4. Verify workflow references analyst agent: `grep 'hive-recall-analyst' hive/workflows/analyze-session.md`
5. Verify workflow references telemetry emit: `grep 'telemetry emit session_summary' hive/workflows/analyze-session.md`
6. Verify installed copy path convention: `grep './.claude/' .claude/hive/workflows/analyze-session.md` should find matches, `grep '~/.claude/' .claude/hive/workflows/analyze-session.md` should find NO matches.
  </verify>
  <done>
The `/hive:analyze-session` command dispatches to the analyze-session workflow. The workflow orchestrates the full pipeline: config check, transcript extraction via CLI, analyst agent spawn via Task(), result parsing, session_summary event emission, and user reporting. All 3 mirror copies exist in `.claude/` with correct path conventions. The end-to-end chain is wired: command -> workflow -> CLI extraction -> agent analysis -> event emission.
  </done>
</task>

</tasks>

<verification>
1. The `telemetry transcript` subcommand routes correctly and does not show "Unknown telemetry subcommand"
2. The analyst agent file has valid frontmatter with name, description, tools, color
3. The command/workflow pair follows the insights.md pattern
4. All 3 installed copies exist with correct path conventions (./.claude/ not ~/.claude/)
5. The workflow wires all three components: CLI extraction, agent spawn, event emission
6. Config gating via `transcript_analysis` toggle is enforced at the CLI level
</verification>

<success_criteria>
- `node hive-tools.js telemetry transcript` is a recognized subcommand that checks config, resolves transcripts, extracts/condenses, and outputs structured JSON
- `agents/hive-recall-analyst.md` exists with analysis framework, privacy rules, and JSON output format
- `/hive:analyze-session` command and workflow exist and orchestrate the full extraction -> analysis -> emission pipeline
- All installed mirror copies exist in `.claude/` with correct path conventions
- session_summary events can be emitted by the workflow after analyst completes
</success_criteria>

<output>
After completion, create `.planning/phases/06-transcript-analysis/06-01-SUMMARY.md`
</output>
